import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { searchSimilar, getCollectionStats } from '@/lib/vectorStore';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'your-api-key-here'
});

export async function POST(request: NextRequest) {
  try {
    const { message, limit = 3, responseLength = 'medium' } = await request.json();

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Brak wiadomoÅ›ci do przetworzenia' },
        { status: 400 }
      );
    }

    console.log(`\nğŸ” ===== RAG CHAT TEST =====`);
    console.log(`ğŸ“ Pytanie: "${message}"`);
    console.log(`ğŸ¯ Threshold podobieÅ„stwa: 0.6`);

    // 1. Wyszukaj podobne treÅ›ci w ChromaDB z threshold
    let context = '';
    let searchResults = [];
    let responseSource = 'openai'; // 'database', 'hybrid', 'openai'
    const SIMILARITY_THRESHOLD = 0.3; // Minimum similarity score (lowered from 0.6)
    
    try {
      searchResults = await searchSimilar(message, limit);
      
      console.log(`ğŸ“Š Znaleziono ${searchResults.length} wynikÃ³w w bazie`);
      
      if (searchResults.length > 0) {
        // Loguj wszystkie wyniki z podobieÅ„stwem
        console.log(`ğŸ“ˆ SzczegÃ³Å‚y wynikÃ³w:`);
        searchResults.forEach((result, index) => {
          const isRelevant = result.similarity >= SIMILARITY_THRESHOLD;
          console.log(`  ${index + 1}. ${result.metadata.type} - ${(result.similarity * 100).toFixed(1)}% ${isRelevant ? 'âœ…' : 'âŒ'}`);
        });
        
        // Filtruj wyniki wedÅ‚ug threshold podobieÅ„stwa
        const relevantResults = searchResults.filter(result => result.similarity >= SIMILARITY_THRESHOLD);
        
        if (relevantResults.length > 0) {
          context = relevantResults
            .map((result, index) => 
              `Å¹rÃ³dÅ‚o ${index + 1} (${result.metadata.type}, podobieÅ„stwo: ${(result.similarity * 100).toFixed(1)}%):\n${result.content}\n`
            )
            .join('\n');
          
          responseSource = relevantResults.length === searchResults.length ? 'database' : 'hybrid';
          console.log(`âœ… Wybrano ${relevantResults.length} wysokiej jakoÅ›ci treÅ›ci`);
          console.log(`ğŸ¯ Response source: ${responseSource.toUpperCase()}`);
        } else {
          console.log(`âŒ Wszystkie treÅ›ci majÄ… zbyt niskie podobieÅ„stwo (max: ${Math.max(...searchResults.map(r => r.similarity)).toFixed(3)})`);
          console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
        }
      } else {
        console.log('âŒ Brak podobnych treÅ›ci w bazie danych');
        console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
      }
    } catch (searchError) {
      console.error('âŒ BÅ‚Ä…d wyszukiwania w ChromaDB:', searchError);
      console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
      // Kontynuuj bez kontekstu jeÅ›li wyszukiwanie siÄ™ nie powiedzie
    }

    // 2. Przygotuj smart prompt z kontekstem
    const hasContext = context.length > 0;
    
    // Determine response length instructions
    let lengthInstruction = '';
    switch (responseLength) {
      case 'short':
        lengthInstruction = 'Odpowiadaj BARDZO ZWIÄ˜Å¹LE (2-3 zdania maksymalnie).';
        break;
      case 'detailed':
        lengthInstruction = 'MoÅ¼esz udzieliÄ‡ peÅ‚nej, szczegÃ³Å‚owej odpowiedzi.';
        break;
      default: // 'medium'
        lengthInstruction = 'Odpowiadaj ZWIÄ˜Å¹LE (3-5 zdaÅ„ maksymalnie).';
    }

    let systemPrompt = `JesteÅ› ekspertem siatkÃ³wki w VolleyInsight. 

ZASADY ODPOWIEDZI:
- Odpowiadaj KONKRETNIE i ZWIÄ˜Å¹LE (3-5 zdaÅ„ max)
- UÅ¼ywaj bullet points dla list elementÃ³w
- KrÃ³tkie paragrafy (max 2-3 zdania kaÅ¼dy)
- Struktura: GÅ‚Ã³wna odpowiedÅº â†’ Opcjonalne detale

FORMATOWANIE:
- Numerowane listy dla krokÃ³w (1. 2. 3.)
- Bullet points (â€¢) dla cech/elementÃ³w
- Pogrubienie dla kluczowych terminÃ³w
- PodziaÅ‚ na sekcje tylko gdy niezbÄ™dne

PRZYKÅAD DOBREJ ODPOWIEDZI:
"Blok wymaga trzech kluczowych elementÃ³w:
- Pozycja: stopy na szerokoÅ›Ä‡ barkÃ³w, kolana lekko ugiÄ™te
- Timing: skok dokÅ‚adnie w momencie uderzenia przez atakujÄ…cego
- RÄ™ce: maksymalnie wyciÄ…gniÄ™te, palce rozstawione

Kluczowy jest timing - za wczeÅ›nie lub za pÃ³Åºno znaczÄ…co obniÅ¼a skutecznoÅ›Ä‡."

UNIKAJ:
- RozwlekÅ‚ych wprowadzeÅ„
- Powtarzania oczywistoÅ›ci
- Nadmiernych wyjaÅ›nieÅ„
- DÅ‚ugich akapitÃ³w bez podziaÅ‚u

${lengthInstruction}

${hasContext ? 'Bazuj na kontekÅ›cie z bazy wiedzy.' : 'UÅ¼ywaj wiedzy eksperckiej.'}`;

    // Smart prompt logic based on response source
    if (responseSource === 'database') {
      systemPrompt += `\n\nKONTEKST Z BAZY WIEDZY VOLLEYINSIGHT:
${context}

UÅ¼yj powyÅ¼szego kontekstu jako gÅ‚Ã³wnego ÅºrÃ³dÅ‚a informacji. Odpowiadaj na podstawie tych materiaÅ‚Ã³w, dodajÄ…c swoje eksperckie komentarze.`;
    } else if (responseSource === 'hybrid') {
      systemPrompt += `\n\nKONTEKST Z BAZY WIEDZY VOLLEYINSIGHT (czÄ™Å›ciowo odpowiedni):
${context}

UÅ¼yj powyÅ¼szego kontekstu jako punktu wyjÅ›cia, ale uzupeÅ‚nij odpowiedÅº swojÄ… wiedzÄ… eksperckÄ… o siatkÃ³wce.`;
    } else {
      systemPrompt += `\n\nNie masz dostÄ™pu do bazy wiedzy VolleyInsight, wiÄ™c odpowiadaj na podstawie swojej wiedzy eksperckiej o siatkÃ³wce.`;
    }

    // 3. Generuj odpowiedÅº uÅ¼ywajÄ…c OpenAI
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: systemPrompt
        },
        {
          role: "user",
          content: message
        }
      ],
      max_tokens: 1000,
      temperature: 0.7,
    });

    const response = completion.choices[0]?.message?.content || 'Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi.';

    // 4. Przygotuj smart response z metadanymi
    const responseData = {
      success: true,
      message: response,
      context: {
        hasContext: context.length > 0,
        responseSource: responseSource,
        responseLength: responseLength,
        sourcesCount: searchResults.length,
        relevantSourcesCount: searchResults.filter(r => r.similarity >= SIMILARITY_THRESHOLD).length,
        similarityThreshold: SIMILARITY_THRESHOLD,
        sources: searchResults.map(result => ({
          type: result.metadata.type,
          filename: result.metadata.filename,
          similarity: result.similarity,
          isRelevant: result.similarity >= SIMILARITY_THRESHOLD,
          content: result.content.substring(0, 100) + '...'
        }))
      },
      timestamp: new Date().toISOString()
    };

    console.log(`âœ… OdpowiedÅº wygenerowana (${response.length} znakÃ³w)`);
    console.log(`ğŸ¯ Final response source: ${responseSource.toUpperCase()}`);
    console.log(`ğŸ“ Response length: ${responseLength.toUpperCase()}`);
    console.log(`ğŸ“Š Context length: ${context.length} znakÃ³w`);
    console.log(`===== KONIEC RAG TEST =====\n`);
    
    return NextResponse.json(responseData);

  } catch (error) {
    console.error('âŒ BÅ‚Ä…d API chat:', error);
    
    return NextResponse.json(
      {
        success: false,
        error: 'BÅ‚Ä…d podczas generowania odpowiedzi',
        details: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d',
        message: 'Przepraszam, wystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania Twojego pytania. SprÃ³buj ponownie.'
      },
      { status: 500 }
    );
  }
}

// GET endpoint do sprawdzenia statusu
export async function GET() {
  try {
    const stats = await getCollectionStats();
    
    return NextResponse.json({
      success: true,
      status: 'RAG Chat API dziaÅ‚a',
      database: {
        connected: true,
        totalChunks: stats?.totalChunks || 0,
        types: stats?.typeDistribution || {}
      },
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    return NextResponse.json(
      {
        success: false,
        status: 'RAG Chat API - bÅ‚Ä…d poÅ‚Ä…czenia z bazÄ… danych',
        error: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d'
      },
      { status: 500 }
    );
  }
}

