import { NextRequest, NextResponse } from 'next/server';
import OpenAI from 'openai';
import { searchSimilar, getCollectionStats } from '@/lib/vectorStore';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY || 'your-api-key-here'
});

export async function POST(request: NextRequest) {
  try {
    const { message, limit = 3 } = await request.json();

    if (!message || typeof message !== 'string') {
      return NextResponse.json(
        { error: 'Brak wiadomoÅ›ci do przetworzenia' },
        { status: 400 }
      );
    }

    console.log(`\nğŸ” ===== RAG CHAT TEST =====`);
    console.log(`ğŸ“ Pytanie: "${message}"`);
    console.log(`ğŸ¯ Threshold podobieÅ„stwa: 0.6`);

    // 1. Wyszukaj podobne treÅ›ci w ChromaDB z threshold
    let context = '';
    let searchResults = [];
    let responseSource = 'openai'; // 'database', 'hybrid', 'openai'
    const SIMILARITY_THRESHOLD = 0.3; // Minimum similarity score (lowered from 0.6)
    
    try {
      searchResults = await searchSimilar(message, limit);
      
      console.log(`ğŸ“Š Znaleziono ${searchResults.length} wynikÃ³w w bazie`);
      
      if (searchResults.length > 0) {
        // Loguj wszystkie wyniki z podobieÅ„stwem
        console.log(`ğŸ“ˆ SzczegÃ³Å‚y wynikÃ³w:`);
        searchResults.forEach((result, index) => {
          const isRelevant = result.similarity >= SIMILARITY_THRESHOLD;
          console.log(`  ${index + 1}. ${result.metadata.type} - ${(result.similarity * 100).toFixed(1)}% ${isRelevant ? 'âœ…' : 'âŒ'}`);
        });
        
        // Filtruj wyniki wedÅ‚ug threshold podobieÅ„stwa
        const relevantResults = searchResults.filter(result => result.similarity >= SIMILARITY_THRESHOLD);
        
        if (relevantResults.length > 0) {
          context = relevantResults
            .map((result, index) => 
              `Å¹rÃ³dÅ‚o ${index + 1} (${result.metadata.type}, podobieÅ„stwo: ${(result.similarity * 100).toFixed(1)}%):\n${result.content}\n`
            )
            .join('\n');
          
          responseSource = relevantResults.length === searchResults.length ? 'database' : 'hybrid';
          console.log(`âœ… Wybrano ${relevantResults.length} wysokiej jakoÅ›ci treÅ›ci`);
          console.log(`ğŸ¯ Response source: ${responseSource.toUpperCase()}`);
        } else {
          console.log(`âŒ Wszystkie treÅ›ci majÄ… zbyt niskie podobieÅ„stwo (max: ${Math.max(...searchResults.map(r => r.similarity)).toFixed(3)})`);
          console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
        }
      } else {
        console.log('âŒ Brak podobnych treÅ›ci w bazie danych');
        console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
      }
    } catch (searchError) {
      console.error('âŒ BÅ‚Ä…d wyszukiwania w ChromaDB:', searchError);
      console.log(`ğŸ¯ Response source: OPENAI (fallback)`);
      // Kontynuuj bez kontekstu jeÅ›li wyszukiwanie siÄ™ nie powiedzie
    }

    // 2. Przygotuj smart prompt z kontekstem
    let systemPrompt = `JesteÅ› ekspertem od siatkÃ³wki i trenerem VolleyInsight. 
Odpowiadaj na pytania dotyczÄ…ce techniki, taktyki, przepisÃ³w i treningu siatkÃ³wki.

Odpowiadaj po polsku, profesjonalnie i pomocnie. JeÅ›li pytanie dotyczy konkretnej techniki, podaj szczegÃ³Å‚owe instrukcje.`;

    // Smart prompt logic based on response source
    if (responseSource === 'database') {
      systemPrompt += `\n\nKONTEKST Z BAZY WIEDZY VOLLEYINSIGHT:
${context}

UÅ¼yj powyÅ¼szego kontekstu jako gÅ‚Ã³wnego ÅºrÃ³dÅ‚a informacji. Odpowiadaj na podstawie tych materiaÅ‚Ã³w, dodajÄ…c swoje eksperckie komentarze.`;
    } else if (responseSource === 'hybrid') {
      systemPrompt += `\n\nKONTEKST Z BAZY WIEDZY VOLLEYINSIGHT (czÄ™Å›ciowo odpowiedni):
${context}

UÅ¼yj powyÅ¼szego kontekstu jako punktu wyjÅ›cia, ale uzupeÅ‚nij odpowiedÅº swojÄ… wiedzÄ… eksperckÄ… o siatkÃ³wce.`;
    } else {
      systemPrompt += `\n\nNie masz dostÄ™pu do bazy wiedzy VolleyInsight, wiÄ™c odpowiadaj na podstawie swojej wiedzy eksperckiej o siatkÃ³wce.`;
    }

    // 3. Generuj odpowiedÅº uÅ¼ywajÄ…c OpenAI
    const completion = await openai.chat.completions.create({
      model: "gpt-3.5-turbo",
      messages: [
        {
          role: "system",
          content: systemPrompt
        },
        {
          role: "user",
          content: message
        }
      ],
      max_tokens: 1000,
      temperature: 0.7,
    });

    const response = completion.choices[0]?.message?.content || 'Przepraszam, nie mogÄ™ wygenerowaÄ‡ odpowiedzi.';

    // 4. Przygotuj smart response z metadanymi
    const responseData = {
      success: true,
      message: response,
      context: {
        hasContext: context.length > 0,
        responseSource: responseSource,
        sourcesCount: searchResults.length,
        relevantSourcesCount: searchResults.filter(r => r.similarity >= SIMILARITY_THRESHOLD).length,
        similarityThreshold: SIMILARITY_THRESHOLD,
        sources: searchResults.map(result => ({
          type: result.metadata.type,
          filename: result.metadata.filename,
          similarity: result.similarity,
          isRelevant: result.similarity >= SIMILARITY_THRESHOLD,
          content: result.content.substring(0, 100) + '...'
        }))
      },
      timestamp: new Date().toISOString()
    };

    console.log(`âœ… OdpowiedÅº wygenerowana (${response.length} znakÃ³w)`);
    console.log(`ğŸ¯ Final response source: ${responseSource.toUpperCase()}`);
    console.log(`ğŸ“Š Context length: ${context.length} znakÃ³w`);
    console.log(`===== KONIEC RAG TEST =====\n`);
    
    return NextResponse.json(responseData);

  } catch (error) {
    console.error('âŒ BÅ‚Ä…d API chat:', error);
    
    return NextResponse.json(
      {
        success: false,
        error: 'BÅ‚Ä…d podczas generowania odpowiedzi',
        details: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d',
        message: 'Przepraszam, wystÄ…piÅ‚ bÅ‚Ä…d podczas przetwarzania Twojego pytania. SprÃ³buj ponownie.'
      },
      { status: 500 }
    );
  }
}

// GET endpoint do sprawdzenia statusu
export async function GET() {
  try {
    const stats = await getCollectionStats();
    
    return NextResponse.json({
      success: true,
      status: 'RAG Chat API dziaÅ‚a',
      database: {
        connected: true,
        totalChunks: stats?.totalChunks || 0,
        types: stats?.typeDistribution || {}
      },
      timestamp: new Date().toISOString()
    });
  } catch (error) {
    return NextResponse.json(
      {
        success: false,
        status: 'RAG Chat API - bÅ‚Ä…d poÅ‚Ä…czenia z bazÄ… danych',
        error: error instanceof Error ? error.message : 'Nieznany bÅ‚Ä…d'
      },
      { status: 500 }
    );
  }
}

